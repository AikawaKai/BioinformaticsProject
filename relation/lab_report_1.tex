%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 3.1 (25/3/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Linux and Unix Users Group at Virginia Tech Wiki 
% (https://vtluug.org/wiki/Example_LaTeX_chem_lab_report)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel} 
\usepackage[version=3]{mhchem} % Package for chemical equation typesetting
\usepackage{siunitx} % Provides the \SI{}{} and \si{} command for typesetting SI units
\usepackage{graphicx} % Required for the inclusion of images
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements 
\usepackage{csvsimple}
\usepackage{adjustbox}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{color}
\usepackage{listings}
\usepackage{setspace}
\definecolor{Code}{rgb}{0,0,0}
\definecolor{Decorators}{rgb}{0.5,0.5,0.5}
\definecolor{Numbers}{rgb}{0.5,0,0}
\definecolor{MatchingBrackets}{rgb}{0.25,0.5,0.5}
\definecolor{Keywords}{rgb}{0,0,1}
\definecolor{self}{rgb}{0,0,0}
\definecolor{Strings}{rgb}{0,0.63,0}
\definecolor{Comments}{rgb}{0,0.63,1}
\definecolor{Backquotes}{rgb}{0,0,0}
\definecolor{Classname}{rgb}{0,0,0}
\definecolor{FunctionName}{rgb}{0,0,0}
\definecolor{Operators}{rgb}{0,0,0}
\definecolor{Background}{rgb}{0.98,0.98,0.98}
\lstdefinelanguage{Python}{
numbers=left,
numberstyle=\footnotesize,
numbersep=1em,
xleftmargin=1em,
framextopmargin=2em,
framexbottommargin=2em,
showspaces=false,
showtabs=false,
showstringspaces=false,
frame=l,
tabsize=4,
% Basic
basicstyle=\ttfamily\small\setstretch{1},
backgroundcolor=\color{Background},
% Comments
commentstyle=\color{Comments}\slshape,
% Strings
stringstyle=\color{Strings},
morecomment=[s][\color{Strings}]{"""}{"""},
morecomment=[s][\color{Strings}]{'''}{'''},
% keywords
morekeywords={import,from,class,def,for,while,if,is,in,elif,else,not,and,or,print,break,continue,return,True,False,None,access,as,,del,except,exec,finally,global,import,lambda,pass,print,raise,try,assert},
keywordstyle={\color{Keywords}\bfseries},
% additional keywords
morekeywords={[2]@invariant,pylab,numpy,np,scipy},
keywordstyle={[2]\color{Decorators}\slshape},
emph={self},
emphstyle={\color{self}\slshape},
%
}
\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

% CSV import

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Predizione della funzione delle proteine con
metodi di Machine Learning} % Title

\author{Odore Marco \\ Rossi Lorenzo} % Author name

\date{\today} % Date for the report

\begin{document}

\maketitle % Insert the title, author and date

\begin{center}
\begin{tabular}{l l}

Docente: & Valentini Giorgio \\% Instructor/supervisor
Corso: & Bioinformatica
\end{tabular}
\end{center}

% If you wish to include an abstract, uncomment the lines below
% \begin{abstract}
% Abstract text
% \end{abstract}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Scopo del progetto}

L'obiettivo del progetto è di predire la funzione delle proteine di \emph{Drosophila
melanogaster}, per determinate ontologie, tramite gli algoritmi di apprendimento Support Vector Machine(SVM) e Multilayer Perceptron(MLP), per poi analizzarne e confrontarne i risultati. Dato che ogni proteina può essere classificata in più di una categoria, il problema trattato è quello della classificazione multi-etichetta.

\section{Dataset}
Il dataset utilizzato per l'apprendimento induttivo è stato generato da un grafo indiretto, i cui nodi sono le proteine e gli archi indicano il grado di similitudine tra due proteine\footnote{Come è stata costruita la matrice:\\ \url{https://homes.di.unimi.it/~valentini/SlideCorsi/Bioinformatica1617/Bioinf-Project1617.pdf}}. Tale grafo è rappresentato da una matrice pesata  di  adiacenza e ogni  riga  (colonna)  si  riferisce quindi  ad  una  diversa  proteina  dell'organismo  ed  ogni  entry  al  peso  dell'arco che connette due proteine.

\subsection{Istanze degli algoritmi}
Le istanze utilizzate per i due algoritmi induttivi sono le righe (colonne) della matrice di adiacenza. Quindi per ogni proteina si avrà un vettore le cui componenti (feature) rappresentano il grado di similitudine che questa ha in relazione alle altre proteine. 

\subsection{Etichettatura}
Per l'etichettatura delle istanze sono state fornite tre ontologie\footnote{Tutti i dataset utilizzati sono scaricabili dal sito:
\url{http://homes.di.unimi.it/valentini/DATA/ProgettoBioinf1617}}
\begin{itemize}
\item BP(Biological Process) con 1951 termini.
\item MF (Molecular Function) con 234 termini.
\item CC (Cellular Component) con 235 termini.
\end{itemize} 
Rappresentate da matrici di annotazioni, dove sulle righe sono specificate le proteine e sulle colonne i termini delle ontologie. Nell'entry $(i,j)$ della matrice è specificato un 1 se la proteina $i$ appartiene alla categoria\textbackslash termine $j$, 0 altrimenti.
\newline
\newline
Data la notevole quantità di tempo necessaria per l'addestramento dei classificatori, ci si è soffermati unicamente sull'ontologia CC. Quindi ad ogni istanza del problema è stato associato un sottoinsieme di queste etichette.

\section{Metodi di apprendimento}

I metodi di apprendimento supervisionato utilizzati sono:
\begin{itemize}
\item Multilayer Perceptron.
\item Support Vector Machine.
\end{itemize}

\subsection{SVM}
Si tratta di un algoritmo di apprendimento che performa bene su problemi linearmente separabili nello spazio euclideo delle feature. È inoltre applicabile anche a problemi non linearmente separabili, data la possibilità di introduzione dei \emph{kernel}, che proiettano lo spazio a n-dimensioni (n feature) in uno spazio ad elevata dimensionalità, tramite delle trasformazioni non lineari, dove le probabilità che il problema sia linearmente separabile aumentano notevolmente\footnote{Teorema di Cover}.
\newline
\newline
Data l'altissima probabilità dei diversi problemi di classificazione di essere non linearmente separabili, nel nostro set-up è stato utilizzato il kernel Gaussiano RBF\footnote{\url{https://en.wikipedia.org/wiki/Radial_basis_function_kernel}}.

\subsection{MLP}
Si tratta della naturale evoluzione del \textit{Perceptron} (algoritmo adatto a problemi linearmente separabili) che comporta l'introduzione di nuove funzioni di attivazione non lineari per i neuroni, che permettono la gestione anche di problemi non linearmente separabili. La rete neurale multilayer possiede inoltre almeno un layer aggiuntivo (oltre quello di input e quello di output del Perceptron), chiamato \textit{hidden layer} ed è in grado di fornire approssimazioni delle soluzioni di numerosi problemi\footnote{G. Cybenko, nel 1989, ha dimostrato che sono, infatti, approssimatori universali}. L'addestramento di queste reti avviene tramite il metodo della \textit{backpropagation}\footnote{\url{https://en.wikipedia.org/wiki/Backpropagation}}, che comporta la modulazione dei pesi degli archi che collegano un layer al successivo nella rete, i quali permettono di ridurre l'errore di predizione del classificatore.
\newline
\newline
Questo metodo è un metodo approssimato (porta ad un minimo locale della funzione di perdita), dato che in generale il problema di ottimizzazione dei pesi degli archi risulta essere un problema NP-Completo.

\section{Set-up sperimentale}

Dato il tempo limitato per l'esplorazione delle diverse configurazioni di ogni algoritmo, ci si è focalizzati unicamente su determinati set-up di apprendimento, utilizzando le implementazioni degli algoritmi in python fornite da \textit{Scikit-learn}\footnote{\url{http://scikit-learn.org/stable/}}.
\newline
\newline
Per ogni singolo problema di classificazione è stato addestrato un singolo classificatore, cercando di gestire lo sbilanciamento delle classi.

\subsection{Set-up SVM}
Per la support vector machine, come anticipato, è stato utilizzato il kernel RBF. Si tratta di una funzione kernel che può essere interpretata come similarità tra due istanze del problema (sfrutta la distanza euclidea) ed è regolata da un paramatro $\gamma$ , che nel nostro test è stato fissato a $\frac{1}{\#features}$.
\newline
\newline
Per la gestione delle classi sbilanciate si è fissato il parametro $class\_weight$ dell'implementazione python di scikit-learn a $"balanced"$, il quale permette di modulare automaticamente la penalità per le istanze delle classi sbilanciate, proporzionalmente alla loro frequenza, migliorando notevolmente le prestazioni dell'algoritmo su queste ultime.

\subsection{Set-up MLP}
Per la rete neurale multilayer si è decisa una configurazione a due hidden layer da 500 nodi ciascuno.
\newline
\newline
Per le funzioni di attivazione e il solver, si sono utilizzate le configurazioni di default dell'algoritmo, e cioè $Relu$ per le funzioni di attivazione e $Adam$ come solver.
\newline
\newline
La Relu è la funzione:
\[
 f(x) = max(0, x)
 \]
ed è in genere utilizzata perché veloce per l'apprendimento (per la computazione del gradiente).
\newline
\newline
Il solver Adam è invece un ottimizzatore stocastico per la discesa del gradiente\footnote{\url{https://arxiv.org/abs/1412.6980}}.
\newline
\newline
Per la gestione del problema dello sbilanciamento delle classi, data l'impossibilità di modificare le penalità dall'implementazione python di scikit-learn, si è utilizzata una tecnica di \textit{under-sampling}, la quale consiste nel ridurre la numerosità del dataset sfruttando tecniche di \textit{clustering}, e cioè eliminando un insieme di punti, rappresentandoli unicamente con il rispettivo \textit{centroide}.
\subsection{Metriche e valutazione}

Per valutare le performance del metodo si è usata la tecnica sperimentale della 5-fold
cross-validation, con creazione di fold \textit{stratificati}, e cioè fold che cercano di mantenere inalterate le percentuali delle classi\footnote{Questo perché il dataset è fortemente sbilanciato, e una separazione che non tiene conto delle percentuali porterebbe alla generazione di fold con forte \emph{bias}.}.  Si sono poi utilizzate le seguenti metriche:

\begin{itemize}
\item Misure per  class:   Area  Under  the  Receiver  Operating  Characteristic
curve (AUROC) and the Area Under the Precision Recall Curve (AUPRC);
\item Misure per-example: la Precision, Recall ed F-score gerarchica.
\end{itemize}

\section{Risultati per l'ontologia CC}
\subsection{AUROC AUPRC: MLP vs SVM}
\begin{longtable}{lllll} 
\toprule
\bfseries Class & \bfseries AUROC\_mlp & \bfseries AUPRC\_mlp  & \bfseries AUROC\_svm & \bfseries AUPRC\_svm\\
\midrule \endhead
\bottomrule \endfoot
\csvreader[
    late after line=\\,
    late after last line=,
    before reading={\catcode`\#=12},
    after reading={\catcode`\#=6}]%
    {new_csv.csv}{1=\AUC,2=\ROC,3=\PRC,4=\ROCC,5=\PRCC}{\AUC & \ROC & \PRC & \ROCC & \PRCC}
\end{longtable}
\subsection{Multilabel Precision, Multilabel Recall, Multilabel F-Score: MLP vs SVM}
Le seguenti metriche sono state ottenute fissando la soglia dei classificatori a 0.5.
\begin{longtable}{lcl} 
\toprule
\bfseries Metrica & \bfseries MLP & \bfseries SVM \\
\midrule \endhead
\bottomrule \endfoot
\csvreader[
    late after line=\\,
    late after last line=,
    before reading={\catcode`\#=12},
    after reading={\catcode`\#=6}]%
    {new_csv1.csv}{1=\metrica,2=\mlp,3=\svm}{\metrica & \mlp & \svm}
\end{longtable}

\section{Codice}

Di seguito il codice utilizzato nel progetto\footnote{È possibile scaricarlo dalla repository git \url{https://github.com/AikawaKai/BioinformaticsProject}}.
\newline
\textbf{MLPevaluation.py}
\lstinputlisting[language=Python]{../MLPevaluation.py}


\textbf{SVMevaluation.py}
\lstinputlisting[language=Python]{../SVMevaluation.py}

\textbf{utility/loadDataSet.py}
\lstinputlisting[language=Python]{../utility/loadDataSet.py}

\textbf{utility/scorer.py}
\lstinputlisting[language=Python]{../utility/scorer.py}




\end{document}