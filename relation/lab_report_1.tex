%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 3.1 (25/3/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Linux and Unix Users Group at Virginia Tech Wiki 
% (https://vtluug.org/wiki/Example_LaTeX_chem_lab_report)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel} 
\usepackage[version=3]{mhchem} % Package for chemical equation typesetting
\usepackage{siunitx} % Provides the \SI{}{} and \si{} command for typesetting SI units
\usepackage{graphicx} % Required for the inclusion of images
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements 
\usepackage{csvsimple}
\usepackage{adjustbox}
\usepackage{longtable}
\usepackage{booktabs}
\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

% CSV import
\begin{filecontents*}{grade.csv}
AUC,ROC,PRC
GO:0000124,0.9349071264,0.2314905989
GO:0000151,0.8537180475,0.0827923386
GO:0000228,0.9034482759,0.0576105693
GO:0000323,0.8973557286,0.2186968037
GO:0000428,0.8559061628,0.0281001161
GO:0000775,0.9164873196,0.3859763414
GO:0000776,0.8295349611,0.0487930732
GO:0000785,0.64144427,0.0311578373
GO:0000790,0.9118897721,0.23239818
GO:0000791,0.9166631312,0.1144489562
GO:0000792,0.9333641728,0.0872317585
GO:0000793,0.97710147,0.1383859604
GO:0000794,0.7188128807,0.0171022356
GO:0000922,0.9028213166,0.0378969861
GO:0000932,0.8565057808,0.0778772264
GO:0005575,0.9461538462,0.2421571525
GO:0005576,0.9852134787,0.9890539821
GO:0005578,0.7612264365,0.5875740022
GO:0005604,0.7571512232,0.0346979006
GO:0005615,0.8201195356,0.041202666
GO:0005622,0.835168346,0.6696000125
GO:0005623,0.9980627166,0.9981007882
GO:0005634,0.9965473808,0.997651379
GO:0005635,0.9937295111,0.9810569636
GO:0005643,0.8736923918,0.0709133525
GO:0005652,0.8810984582,0.0491795251
GO:0005654,0.9194357367,0.0284187975
GO:0005657,0.9497794634,0.6525043518
GO:0005667,0.9840125392,0.3481045752
GO:0005669,0.9367454658,0.3421056575
GO:0005681,0.8661710257,0.0641645019
GO:0005694,0.9632907033,0.5420981868
GO:0005700,0.9050768562,0.408744437
GO:0005701,0.9137107302,0.2895584911
GO:0005703,0.910031348,0.0200471207
GO:0005705,0.7909248254,0.0847809346
GO:0005719,0.8546236782,0.0758675995
GO:0005721,0.9504702194,0.0374885349
GO:0005730,0.9122257053,0.0614028091
GO:0005737,0.8806844025,0.0596654436
GO:0005739,0.9672915622,0.9175578372
GO:0005740,0.8548607775,0.2657256108
GO:0005743,0.9084097693,0.0638023033
GO:0005764,0.9115987461,0.0410280571
GO:0005768,0.8656471607,0.0469203211
GO:0005770,0.8905597649,0.0972162853
GO:0005773,0.7177285768,0.0092521625
GO:0005783,0.8666926669,0.0221624007
GO:0005789,0.898012971,0.2633308354
GO:0005794,0.9265306122,0.0613208353
GO:0005795,0.9170496217,0.3064702799
GO:0005811,0.7501149097,0.0215396258
GO:0005813,0.9076369283,0.3947099007
GO:0005814,0.8706632143,0.1181346392
GO:0005815,0.7783669532,0.0784073498
GO:0005819,0.8423269314,0.0848594103
GO:0005828,0.8704523867,0.2051710802
GO:0005829,0.8636363636,0.0431397849
GO:0005840,0.9098002103,0.0954196616
GO:0005856,0.9950576919,0.8820791353
GO:0005874,0.9598473839,0.7835189691
GO:0005875,0.8947486753,0.3330651168
GO:0005876,0.936342757,0.6484923202
GO:0005886,0.8379905808,0.2537620056
GO:0005887,0.8508175344,0.550692185
GO:0005911,0.8322882104,0.1957553444
GO:0005912,0.8516726944,0.1609713698
GO:0005918,0.8816980303,0.1542566341
GO:0005920,0.8100228238,0.1911781301
GO:0005921,0.6862068966,0.0140889915
GO:0005924,0.9370518644,0.7143589744
GO:0005929,0.7910161267,0.0277671255
GO:0005938,0.8821065634,0.0320785146
GO:0008021,0.8565922031,0.1060811661
GO:0008023,0.8910417169,0.239817662
GO:0008180,0.9602961504,0.1884033856
GO:0009986,0.9918487916,0.7557622739
GO:0010369,0.8899301956,0.1557925075
GO:0012505,0.967845209,0.1094298246
GO:0015629,0.8673534073,0.1037326438
GO:0015630,0.8647244094,0.2122499679
GO:0016020,0.9616214375,0.7866516831
GO:0016021,0.8995339954,0.6829655464
GO:0016023,0.8597634857,0.1286408997
GO:0016027,0.8992387659,0.1794763494
GO:0016028,0.8993602457,0.3007700236
GO:0016323,0.8036786309,0.1398868774
GO:0016324,0.7855572998,0.1270891474
GO:0016327,0.8313417191,0.2069388125
GO:0016459,0.6487613372,0.0378838202
GO:0016460,0.9384615385,0.5742544547
GO:0016461,0.8489028213,0.014673869
GO:0016469,0.9454545455,0.4076584507
GO:0016591,0.8464678179,0.4251660511
GO:0016592,0.8882834646,0.3003545572
GO:0016604,0.9456686704,0.8835600313
GO:0017053,0.8584053877,0.1835299907
GO:0019866,0.8968602826,0.0421628576
GO:0019897,0.7919152276,0.0406772954
GO:0019898,0.7430094389,0.1227077182
GO:0030016,0.7652756797,0.0732665041
GO:0030017,0.9479655191,0.0794058993
GO:0030018,0.8894780796,0.2190320734
GO:0030054,0.8348762075,0.1007546715
GO:0030055,0.818660768,0.2217321905
GO:0030135,0.9358702873,0.0494290227
GO:0030136,0.9412677843,0.1861380009
GO:0030139,0.9231102456,0.0949219171
GO:0030312,0.9262793361,0.062648653
GO:0030424,0.8670738129,0.3660736903
GO:0030425,0.7994646945,0.1042251641
GO:0030496,0.6238210835,0.164191589
GO:0030529,0.8053670467,0.1144981438
GO:0030880,0.9409808976,0.4981338229
GO:0030894,0.9051472466,0.3106674069
GO:0031010,0.9789968652,0.2566760037
GO:0031011,0.9144200627,0.0291632974
GO:0031012,0.7763278593,0.2341514938
GO:0031090,0.8049114856,0.1034771157
GO:0031224,0.8872498559,0.0991472748
GO:0031226,0.7825149183,0.2219475487
GO:0031252,0.7814802985,0.244634205
GO:0031253,0.8556391884,0.5268994211
GO:0031300,0.7266216542,0.1564015534
GO:0031410,0.6576802508,0.0064392967
GO:0031430,0.9070612733,0.1381922835
GO:0031514,0.9278996865,0.0882532068
GO:0031519,0.8921630094,0.0173431799
GO:0031523,0.9570230608,0.1005064308
GO:0031594,0.8811828566,0.0847294794
GO:0031672,0.8548764423,0.0586101645
GO:0031674,0.8392774713,0.0534650165
GO:0031965,0.8913709443,0.1827484791
GO:0031966,0.8147672525,0.0128502487
GO:0031967,0.8980174997,0.0464863207
GO:0031970,0.8792247498,0.1121678763
GO:0031974,0.7742946708,0.0143124051
GO:0031975,0.9545470085,0.7667865088
GO:0031981,0.8729066603,0.1064192081
GO:0031982,0.9528026675,0.7778997031
GO:0031984,0.9056948813,0.115822141
GO:0031985,0.8980315251,0.0279883729
GO:0031988,0.8801976349,0.0494912034
GO:0032991,0.8800533736,0.1384712966
GO:0032993,0.9827173073,0.948083265
GO:0033176,0.9858801297,0.2864872768
GO:0033181,0.8215070644,0.1468402335
GO:0033202,0.7394034537,0.4039654158
GO:0033267,0.9601644661,0.2335978836
GO:0034399,0.7103773585,0.0348369488
GO:0034708,0.9494505495,0.0725555074
GO:0035003,0.8290196775,0.166354506
GO:0035097,0.8934169279,0.0283466839
GO:0035098,0.9351334051,0.1949366718
GO:0035102,0.925630035,0.1785766277
GO:0035267,0.9376175549,0.0528488971
GO:0035327,0.9032088601,0.0471867387
GO:0035770,0.9532900597,0.2816605279
GO:0042175,0.932580721,0.2690443252
GO:0042995,0.9073346465,0.059843532
GO:0043005,0.8300404618,0.2406122379
GO:0043025,0.7219819458,0.1361918251
GO:0043073,0.6985345389,0.0396528545
GO:0043186,0.9499975394,0.1510179719
GO:0043189,0.8904238619,0.2803753194
GO:0043195,0.938973588,0.0520645013
GO:0043226,0.7161695447,0.0331675122
GO:0043227,0.9972013239,0.9966309849
GO:0043228,0.991562204,0.9834182422
GO:0043229,0.94960217,0.8394860872
GO:0043231,0.9943329903,0.9940598987
GO:0043232,0.9954324568,0.9898813023
GO:0043233,0.9924321881,0.9771802946
GO:0043234,0.96895525,0.8129241699
GO:0043235,0.9767097596,0.9303174608
GO:0043292,0.658435653,0.1039064685
GO:0043296,0.9405660377,0.1068567913
GO:0043596,0.8729133858,0.1227099585
GO:0043601,0.9614420063,0.0554771757
GO:0043679,0.9764890282,0.4266427547
GO:0044297,0.7909693631,0.0350005086
GO:0044306,0.5913752548,0.0360417009
GO:0044420,0.7005945387,0.0261306947
GO:0044421,0.812518516,0.0311849921
GO:0044422,0.7654952515,0.5699174239
GO:0044424,0.993411657,0.9837749708
GO:0044425,0.9963758224,0.9964265125
GO:0044427,0.8505556321,0.3465488232
GO:0044428,0.9229838964,0.3528905321
GO:0044429,0.9697271916,0.9010343397
GO:0044430,0.9207954902,0.0707731091
GO:0044431,0.976736705,0.8448243231
GO:0044432,0.8398904555,0.0376391096
GO:0044444,0.9059519801,0.0681406213
GO:0044446,0.9604561434,0.8406584576
GO:0044448,0.9934694686,0.9795065725
GO:0044449,0.8855429687,0.0975494909
GO:0044450,0.9349056604,0.1032311279
GO:0044451,0.9365587019,0.0502918171
GO:0044454,0.9580403767,0.5562870089
GO:0044456,0.9151898734,0.2388085674
GO:0044459,0.7548617984,0.1234387776
GO:0044463,0.8585272873,0.3250337277
GO:0044464,0.7343421564,0.1618447885
GO:0045169,0.9962244904,0.9971838905
GO:0045170,0.8169704023,0.0527769537
GO:0045171,0.9181414644,0.2206535001
GO:0045172,0.74067312,0.034435367
GO:0045177,0.8538621477,0.1608182779
GO:0045178,0.8868294867,0.1455401387
GO:0045179,0.6178683386,0.0051760386
GO:0045202,0.7991205839,0.0255855052
GO:0045211,0.7761279105,0.1540147934
GO:0045495,0.5778994405,0.0132498799
GO:0046930,0.8851831831,0.2755238486
GO:0048471,0.9446004734,0.0670172802
GO:0048786,0.8841752918,0.0447593478
GO:0051233,0.8471673647,0.0268158016
GO:0055029,0.802300409,0.0241794143
GO:0060293,0.9476602002,0.3307947114
GO:0070013,0.8867657949,0.3090805287
GO:0070160,0.9612750679,0.7687573577
GO:0070161,0.8255171977,0.1913524757
GO:0070461,0.8832273281,0.156853889
GO:0070603,0.8338659992,0.0388469065
GO:0070864,0.9326794764,0.1055251305
GO:0071011,0.9542201641,0.1428804137
GO:0071013,0.9507577998,0.440463976
GO:0071944,0.9543643139,0.4211051382
GO:0072686,0.9298412301,0.6933956051
GO:0090544,0.8613940247,0.0297241641
GO:0097060,0.939184953,0.1206494814
GO:0097346,0.6267468984,0.0095375663
GO:0097458,0.7882292584,0.164490213
\end{filecontents*}

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Predizione della funzione delle proteine con
metodi di Machine Learning} % Title

\author{Odore Marco \\ Rossi Lorenzo} % Author name

\date{\today} % Date for the report

\begin{document}

\maketitle % Insert the title, author and date

\begin{center}
\begin{tabular}{l l}

Docente: & Valentini Giorgio \\% Instructor/supervisor
Corso: & Bioinformatica
\end{tabular}
\end{center}

% If you wish to include an abstract, uncomment the lines below
% \begin{abstract}
% Abstract text
% \end{abstract}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Scopo del progetto}

L'obiettivo del progetto è di predire la funzione delle proteine di \emph{Drosophila
melanogaster}, per determinate ontologie, tramite gli algoritmi di apprendimento Support Vector Machine(SVM) e Multilayer Perceptron(MLP), per poi analizzarne e confrontarne i risultati. Dato che ogni proteina può essere classificata in più di una categoria, il problema trattato è quello della classificazione multi-etichetta.

\section{Dataset}
Il dataset utilizzato per l'apprendimento induttivo è stato generato da un grafo indiretto, i cui nodi sono le proteine e gli archi indicano il grado di similitudine tra due proteine\footnote{Come è stata costruita la matrice:\\ \url{https://homes.di.unimi.it/~valentini/SlideCorsi/Bioinformatica1617/Bioinf-Project1617.pdf}}. Tale grafo è rappresentato da una matrice pesata  di  adiacenza e ogni  riga  (colonna)  si  riferisce quindi  ad  una  diversa  proteina  dell'organismo  ed  ogni  entry  al  peso  dell'arco che connette due proteine.

\subsection{Istanze degli algoritmi}
Le istanze utilizzate per i due algoritmi induttivi sono le righe (colonne) della matrice di adiacenza. Quindi per ogni proteina si avrà un vettore le cui componenti (feature) rappresentano il grado di similitudine che questa ha in relazione alle altre proteine. 

\subsection{Etichettatura}
Per l'etichettatura delle istanze sono state fornite tre ontologie\footnote{Tutti i dataset utilizzati sono scaricabili dal sito:
\url{http://homes.di.unimi.it/valentini/DATA/ProgettoBioinf1617}}
\begin{itemize}
\item BP(Biological Process) con 1951 termini.
\item MF (Molecular Function) con 234 termini.
\item CC (Cellular Component) con 235 termini.
\end{itemize} 
Rappresentate da matrici di annotazioni, dove sulle righe sono specificate le proteine e sulle colonne i termini delle ontologie. Nell'entry $(i,j)$ della matrice è specificato un 1 se la proteina $i$ appartiene alla categoria\textbackslash termine $j$, 0 altrimenti.
\newline
\newline
Data la notevole quantità di tempo necessaria per l'addestramento dei classificatori, ci si è soffermati unicamente sull'ontologia CC. Quindi ad ogni istanza del problema è stato associato un sottoinsieme di queste etichette.

\section{Metodi di apprendimento}

I metodi di apprendimento supervisionato utilizzati sono:
\begin{itemize}
\item Multilayer Perceptron.
\item Support Vector Machine.
\end{itemize}

\subsection{SVM}
Si tratta di un algoritmo di apprendimento che performa bene su problemi linearmente separabili nello spazio euclideo delle feature. È inoltre applicabile anche a problemi non linearmente separabili, data la possibilità di introduzione dei \emph{kernel}, che proiettano lo spazio a n-dimensioni (n feature) in uno spazio ad elevata dimensionalità, tramite delle trasformazioni non lineari, dove le probabilità che il problema sia linearmente separabile aumentano notevolmente\footnote{Teorema di Cover}.
\newline
\newline
Data l'altissima probabilità dei diversi problemi di classificazione di essere non linearmente separabili, nel nostro set-up è stato utilizzato il kernel Gaussiano RBF\footnote{\url{https://en.wikipedia.org/wiki/Radial_basis_function_kernel}}.

\subsection{MLP}
Si tratta della naturale evoluzione del \textit{Perceptron} (algoritmo adatto a problemi linearmente separabili) che comporta l'introduzione di nuove funzioni di attivazione non lineari per i neuroni, che permettono la gestione anche di problemi non linearmente separabili. La rete neurale multilayer possiede inoltre almeno un layer aggiuntivo (oltre quello di input e quello di output del Perceptron), chiamato \textit{hidden layer} ed è in grado di fornire approssimazioni delle soluzioni di numerosi problemi\footnote{G. Cybenko, nel 1989, ha dimostrato che sono, infatti, approssimatori universali}. L'addestramento di queste reti avviene tramite il metodo della \textit{backpropagation}\footnote{\url{https://en.wikipedia.org/wiki/Backpropagation}}, che comporta la modulazione dei pesi degli archi che collegano un layer al successivo nella rete, i quali permettono di ridurre l'errore di predizione del classificatore.
\newline
\newline
Questo metodo è un metodo approssimato (porta ad un minimo locale della funzione di perdita), dato che in generale il problema di ottimizzazione dei pesi degli archi risulta essere un problema NP-Completo.

\section{Set-up sperimentale}

Dato il tempo limitato per l'esplorazione delle diverse configurazioni di ogni algoritmo, ci si è focalizzati unicamente su determinati set-up di apprendimento, utilizzando le implementazioni degli algoritmi in python fornite da \textit{Scikit-learn}\footnote{\url{http://scikit-learn.org/stable/}}.
\newline
\newline
Per ogni singolo problema di classificazione è stato addestrato un singolo classificatore, cercando di gestire lo sbilanciamento delle classi.

\subsection{Set-up SVM}
Per la support vector machine, come anticipato, è stato utilizzato il kernel RBF. Si tratta di una funzione kernel che può essere interpretata come similarità tra due istanze del problema (sfrutta la distanza euclidea) ed è regolata da un paramatro $\gamma$ , che nel nostro test è stato fissato a $\frac{1}{\#features}$.
\newline
\newline
Per la gestione delle classi sbilanciate si è fissato il parametro $class\_weight$ dell'implementazione python di scikit-learn ad $"auto"$, il quale permette di modulare automaticamente la penalità per le istanze delle classi sbilanciate, proporzionalmente alla loro frequenza, migliorando notevolmente le prestazioni dell'algoritmo su queste ultime.

\subsection{Set-up MLP}
Per la rete neurale multilayer si è decisa una configurazione a due hidden layer da 500 nodi ciascuno.
\newline
\newline
Per le funzioni di attivazione e il solver, si sono utilizzate le configurazioni di default dell'algoritmo, e cioè $Relu$ per le funzioni di attivazione e $Adam$ come solver.
\newline
\newline
La Relu è la funzione:
\[
 f(x) = max(0, x)
 \]
ed è in genere utilizzata perché veloce per l'apprendimento (per la computazione del gradiente).
\newline
\newline
Il solver Adam è invece un ottimizzatore stocastico per la discesa del gradiente\footnote{\url{https://arxiv.org/abs/1412.6980}}.
\newline
\newline
Per la gestione del problema dello sbilanciamento delle classi, data l'impossibilità di modificare le penalità dall'implementazione python di scikit-learn, si è utilizzata una tecnica di \textit{under-sampling}, la quale consiste nel ridurre la numerosità del dataset sfruttando tecniche di \textit{clustering}, e cioè eliminando un insieme di punti, rappresentandoli unicamente con il rispettivo \textit{centroide}.
\subsection{Metriche e valutazione}

Per valutare le performance del metodo si è usata la tecnica sperimentale della 5-fold
cross-validation, con creazione di fold \textit{stratificati}, e cioè fold che cercano di mantenere inalterate le percentuali delle classi\footnote{Questo perché il dataset è fortemente sbilanciato, e una separazione che non tiene conto delle percentuali porterebbe alla generazione di fold con forte \emph{bias}.}.  Si sono poi utilizzate le seguenti metriche:

\begin{itemize}
\item Misure per  class:   Area  Under  the  Receiver  Operating  Characteristic
curve (AUROC) and the Area Under the Precision Recall Curve (AUPRC);
\item Misure per-example: la Precision, Recall ed F-score gerarchica.
\end{itemize}

\section{Risultati}
\subsection{AUROC AUPRC: MLP vs SVM}
\begin{longtable}{lll} 
\toprule
\bfseries Class & \bfseries AUROC & \bfseries AUPRC (\%) \\
\midrule \endhead
\bottomrule \endfoot
\csvreader[
    late after line=\\,
    late after last line=,
    before reading={\catcode`\#=12},
    after reading={\catcode`\#=6}]%
    {new_csv.csv}{1=\AUC,2=\ROC,3=\PRC}{\AUC & \ROC & \PRC}
\end{longtable}
\subsection{Precision, Recall, F-Score: MLP vs SVM}

\section{Codice}




\end{document}